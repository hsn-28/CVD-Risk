{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4c5cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/content/data\")\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIVES_SLUG = \"nitishsingla0/fives-dataset\"\n",
    "FIVES_NAME = \"FIVES\"\n",
    "\n",
    "# Utils\n",
    "def sh(cmd, check=True, echo=True, capture=True):\n",
    "    if echo:\n",
    "        print(\"$\", cmd)\n",
    "    if capture:\n",
    "        p = subprocess.run(cmd, shell=True, text=True, capture_output=True)\n",
    "        if p.stdout:\n",
    "            print(p.stdout)\n",
    "        if p.stderr:\n",
    "            print(p.stderr, file=sys.stderr)\n",
    "    else:\n",
    "        p = subprocess.run(cmd, shell=True)\n",
    "    if check and p.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(p.returncode, cmd)\n",
    "    return p\n",
    "\n",
    "def move_into(src_dir: Path, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for item in src_dir.iterdir():\n",
    "        dst = out_dir / item.name\n",
    "        if item.is_dir():\n",
    "            dst.mkdir(parents=True, exist_ok=True)\n",
    "            for s in item.rglob(\"*\"):\n",
    "                if s.is_file():\n",
    "                    d = dst / s.relative_to(item)\n",
    "                    d.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy2(s, d)\n",
    "        else:\n",
    "            shutil.copy2(item, dst)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(src_dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Kaggle auth\n",
    "def ensure_kaggle_auth():\n",
    "    kaggle_dir = Path(\"/root/.kaggle\")\n",
    "    kaggle_json = kaggle_dir / \"kaggle.json\"\n",
    "    if not kaggle_json.exists():\n",
    "        try:\n",
    "            from google.colab import files\n",
    "        except Exception:\n",
    "            print(\" google.colab not available. If you are not in Colab,\"\n",
    "                  \" place kaggle.json at /root/.kaggle/kaggle.json manually.\")\n",
    "            raise\n",
    "        print(\" Kaggle API token not found. Upload kaggle.json (Kaggle → Account → Create New API Token).\")\n",
    "        kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "        uploaded = files.upload()\n",
    "        fname = next(iter(uploaded))\n",
    "        if fname != \"kaggle.json\":\n",
    "            Path(f\"/content/{fname}\").rename(\"/content/kaggle.json\")\n",
    "            fname = \"kaggle.json\"\n",
    "        shutil.move(f\"/content/{fname}\", kaggle_json)\n",
    "        kaggle_json.chmod(0o600)\n",
    "\n",
    "    try:\n",
    "        creds = json.loads(kaggle_json.read_text())\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = creds.get(\"username\", \"\")\n",
    "        os.environ[\"KAGGLE_KEY\"] = creds.get(\"key\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import kaggle\n",
    "    except Exception:\n",
    "        sh(\"pip -q install kaggle\", check=True)\n",
    "\n",
    "def kaggle_probe(slug: str) -> bool:\n",
    "    p = sh(f'kaggle datasets files -d \"{slug}\"', check=False)\n",
    "    return p.returncode == 0\n",
    "\n",
    "def kaggle_download(slug: str, out_dir: Path):\n",
    "    \"\"\"Download a Kaggle dataset and place contents into out_dir.\"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if not kaggle_probe(slug):\n",
    "        print(f\" Probe failed for {slug}. Skipping.\")\n",
    "        return False\n",
    "\n",
    "    # Snapshot zips/dirs before\n",
    "    before_zips = {p.name for p in Path(\"/content\").glob(\"*.zip\")}\n",
    "    before_dirs = {p.name for p in Path(\"/content\").iterdir() if p.is_dir()}\n",
    "\n",
    "    # Bulk download ZIP to\n",
    "    p = sh(f'kaggle datasets download -d \"{slug}\" -p /content', check=False)\n",
    "    if p.returncode == 0:\n",
    "        new_zips = [p for p in Path(\"/content\").glob(\"*.zip\") if p.name not in before_zips]\n",
    "        if new_zips:\n",
    "            for z in new_zips:\n",
    "                sh(f'unzip -q -o \"{z}\" -d \"{out_dir}\"', check=False)\n",
    "                z.unlink(missing_ok=True)\n",
    "            print(f\" {slug} → {out_dir}\")\n",
    "            return True\n",
    "        else:\n",
    "            after_dirs = {p.name for p in Path(\"/content\").iterdir() if p.is_dir()}\n",
    "            created = sorted(list(after_dirs - before_dirs))\n",
    "            moved_any = False\n",
    "            for dname in created:\n",
    "                src = Path(\"/content\") / dname\n",
    "                if any(src.iterdir()):\n",
    "                    move_into(src, out_dir)\n",
    "                    moved_any = True\n",
    "            if moved_any:\n",
    "                print(f\"✓ {slug} → {out_dir}\")\n",
    "                return True\n",
    "\n",
    "    # per-file download\n",
    "    lst = sh(f'kaggle datasets files -d \"{slug}\"', check=False)\n",
    "    if lst.returncode != 0:\n",
    "        return False\n",
    "    names = []\n",
    "    for line in lst.stdout.splitlines():\n",
    "        s = line.strip()\n",
    "        if (not s) or s.startswith(\"name\") or s.startswith(\"---\") or s.startswith(\"Next Page Token\"):\n",
    "            continue\n",
    "        names.append(s.split()[0])\n",
    "    success_any = False\n",
    "    for fname in names:\n",
    "        print(f\"  ↓ {fname}\")\n",
    "        q = sh(f'kaggle datasets download -d \"{slug}\" -f \"{fname}\" -p /content --force', check=False)\n",
    "        if q.returncode != 0:\n",
    "            print(f\" Failed: {fname}\")\n",
    "            continue\n",
    "        z = Path(\"/content\") / (Path(fname).name + \".zip\")\n",
    "        if z.exists():\n",
    "            sh(f'unzip -q -o \"{z}\" -d \"{out_dir}\"', check=False)\n",
    "            z.unlink(missing_ok=True)\n",
    "            success_any = True\n",
    "        else:\n",
    "            # direct file case\n",
    "            src = Path(\"/content\") / Path(fname).name\n",
    "            if src.exists():\n",
    "                dst = out_dir / src.name\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(src), str(dst))\n",
    "                success_any = True\n",
    "    if success_any:\n",
    "        print(f\"✓ {slug} → {out_dir}\")\n",
    "    return success_any\n",
    "\n",
    "# Run FIVES download\n",
    "print(\"=== Ensuring Kaggle auth ===\")\n",
    "ensure_kaggle_auth()\n",
    "\n",
    "target = BASE / FIVES_NAME\n",
    "if target.exists() and any(target.iterdir()):\n",
    "    print(f\"Skip (exists): {FIVES_NAME} at {target}\")\n",
    "else:\n",
    "    print(f\"\\n=== Kaggle: {FIVES_SLUG} → {target} ===\")\n",
    "    ok = kaggle_download(FIVES_SLUG, target)\n",
    "    if not ok:\n",
    "        print(\" FIVES download failed; please check Kaggle access/slug.\")\n",
    "    else:\n",
    "        print(f\" FIVES dataset ready at: {target}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
